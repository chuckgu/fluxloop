---
sidebar_position: 5
---

# evaluate Command

`fluxloop evaluate experiment` ì†Œë¹„ìëŠ” íŒŒì‹±ëœ íŠ¸ë ˆì´ìŠ¤ë¥¼ ì¢…í•©í•´ì„œ **ë‹¨ì¼ HTML ëŒ€ì‹œë³´ë“œ**ë¡œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ ë‹¤ì„¯ ë‹¨ê³„ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤:

1. **LLM-PT (Per-Trace)** â€“ GPT-5ê°€ ê° íŠ¸ë ˆì´ìŠ¤ë¥¼ 7ê°œ ë©”íŠ¸ë¦­(ì™„ìˆ˜, í™˜ê°, ê´€ë ¨ì„±, ë„êµ¬ ì‚¬ìš©, ë§Œì¡±ë„, ëª…í™•ì„±, í˜ë¥´ì†Œë‚˜)ìœ¼ë¡œ ì±„ì í•˜ê³  ì´ìŠˆ íƒ€ì„ë¼ì¸/í€µí”½ìŠ¤ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
2. **Rule Aggregation** â€“ í†µê³„/íŒ¨ìŠ¤ìœ¨/ì„±ëŠ¥ ì¹´ë“œ/í˜ë¥´ì†Œë‚˜ ê²©ì°¨ë¥¼ ê³„ì‚°í•˜ê³  FAILãƒ»PARTIALãƒ»REVIEW ì¼€ì´ìŠ¤ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
3. **LLM-OV (Overall)** â€“ ì§‘ê³„ ë°ì´í„°ë¥¼ ë‹¤ì‹œ GPT-5ì— ì „ë‹¬í•˜ì—¬ ì„ì› ìš”ì•½, Response Quality ê´€ì°°, ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤.
4. **Data Preparation** â€“ `configs/project.yaml`, `configs/input.yaml`, `configs/evaluation.yaml`, `summary.json` ë“±ì„ í•˜ë‚˜ì˜ í˜ì´ë¡œë“œë¡œ í•©ì¹©ë‹ˆë‹¤.
5. **HTML Rendering** â€“ `evaluation_report/report.html` (ê¸°ë³¸ê°’)ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ íŒŒì¼ í•˜ë‚˜ë§Œ ë¸Œë¼ìš°ì €ë¡œ ì—´ë©´ ëª¨ë“  ì§€í‘œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> `fluxloop evaluate` ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— **ë°˜ë“œì‹œ** `fluxloop parse experiment <experiment_dir>` ë¡œ `per_trace_analysis/per_trace.jsonl`ì„ ë§Œë“¤ì–´ ë‘ì„¸ìš”. íŒŒì¼ì„ ì˜®ê²¼ë‹¤ë©´ `--per-trace` ë¡œ ê²½ë¡œë¥¼ ì§€ì •í•˜ì‹­ì‹œì˜¤.

## Prerequisites

1. `fluxloop run experiment`
2. `fluxloop parse experiment <experiment_dir>`

## Basic Usage

```bash
# Parse â†’ Evaluate
fluxloop parse experiment experiments/demo_run_20231215_123456
fluxloop evaluate experiment experiments/demo_run_20231215_123456

# ì‚¬ìš©ì ì •ì˜ evaluation.yaml ì‚¬ìš©
fluxloop evaluate experiment experiments/demo_run_20231215_123456 \
  --config configs/evaluation.yaml

# ì¶œë ¥ ë””ë ‰í„°ë¦¬ ë³€ê²½(ê¸°ë³¸ê°’: evaluation_report)
fluxloop evaluate experiment experiments/demo_run_20231215_123456 \
  --output dashboards/latest_eval \
  --overwrite
```

ì™„ë£Œë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì‹œì§€ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.

```
ğŸ“Š Evaluating experiment at experiments/demo_run_20231215_123456
ğŸ§µ Per-trace data: â€¦/per_trace_analysis/per_trace.jsonl
ğŸ“ Output: â€¦/evaluation_report
â€¦
âœ… Report ready: â€¦/evaluation_report/report.html
```

## Command Options

| Option | Description | Default |
| --- | --- | --- |
| `experiment_dir` | ì‹¤í—˜ ë””ë ‰í„°ë¦¬ ê²½ë¡œ | í•„ìˆ˜ |
| `--config`, `-c` | `configs/evaluation.yaml` ìœ„ì¹˜ | `configs/evaluation.yaml` |
| `--output`, `-o` | ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•  ë””ë ‰í„°ë¦¬ | `evaluation_report` |
| `--overwrite` | ê¸°ì¡´ ë””ë ‰í„°ë¦¬ë¥¼ ì‚­ì œ í›„ ì¬ìƒì„± | `false` |
| `--llm-api-key` | GPT-5 í˜¸ì¶œì— ì‚¬ìš©í•  API Key | `FLUXLOOP_LLM_API_KEY` ë˜ëŠ” `OPENAI_API_KEY` |
| `--per-trace` | `per_trace_analysis/per_trace.jsonl` ê²½ë¡œ | ìë™ ê°ì§€ |
| `--verbose` | ë‹¨ê³„ë³„ ë¡œê·¸ë¥¼ ìì„¸íˆ ì¶œë ¥ | `false` |

## Pipeline Output

```
experiments/<run>/
â””â”€â”€ evaluation_report/
    â””â”€â”€ report.html
```

`report.html`ì—ëŠ” ë‹¤ìŒ ì„¹ì…˜ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.

- Executive Summary + Pass Rate ê²Œì´ì§€
- Trace Ã— Metric ë§¤íŠ¸ë¦­ìŠ¤
- ì‹¤íŒ¨/ë§ˆì§„/ë¦¬ë·° ì¼€ì´ìŠ¤ íƒ€ì„ë¼ì¸ ë° ì´ìŠˆ ìš”ì•½
- í† í°/í„´/ì§€ì—°ì‹œê°„ ì¹´ë“œ + ì´ìƒì¹˜ ëª©ë¡ + í˜ë¥´ì†Œë‚˜ ê²©ì°¨ ì‹œê°í™”
- LLM-OVê°€ ì‘ì„±í•œ Response Quality ê´€ì°°, íŒ¨í„´, Quick Wins, ì¶”ì²œì¡°ì¹˜

ë³„ë„ì˜ ì •ì  íŒŒì¼ì´ ì—†ìœ¼ë¯€ë¡œ `report.html` í•˜ë‚˜ë§Œ ê³µìœ í•˜ë©´ ë©ë‹ˆë‹¤.

## Configuration Highlights (`configs/evaluation.yaml`)

CLI 0.2.30ë¶€í„°ëŠ” **ë©”íŠ¸ë¦­ ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í…œí”Œë¦¿ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```yaml
evaluation_goal: "ì•ˆì „í•˜ê²Œ ì·¨ì†Œ/í™˜ë¶ˆì„ ì™„ë£Œí•˜ëŠ”ì§€ ê²€ì¦"

metrics:
  task_completion:
    enabled: true
    thresholds: {good: 80, fair: 60}
  hallucination:
    enabled: true
    thresholds: {good: 5, fair: 15}
  relevance:
    enabled: true
    thresholds: {good: 90, fair: 80}
  tool_usage_appropriateness:
    enabled: true
    thresholds: {good: 90, fair: 80}
  user_satisfaction:
    enabled: true
    thresholds: {good: 70, fair: 50}
  clarity:
    enabled: true
    thresholds: {good: 90, fair: 80}
  persona_consistency:
    enabled: true
    thresholds: {good: 85, fair: 70}

# íš¨ìœ¨ì„± ì¹´ë“œ (í† í°/í„´/ì§€ì—°ì‹œê°„) ì´ìƒì¹˜ ê°ì§€ ë°©ì‹
efficiency:
  output_tokens:
    enabled: true
    outlier_mode: statistical
    std_multiplier: 2
  conversation_depth:
    enabled: true
    outlier_mode: statistical
  latency:
    enabled: true
    outlier_mode: statistical

advanced:
  llm_judge:
    model: "gpt-5.1"
    temperature: 0.0
```

- `evaluation_goal` ì€ ë¦¬í¬íŠ¸ ìƒë‹¨ê³¼ LLM í”„ë¡¬í”„íŠ¸ì— ê·¸ëŒ€ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
- ê° `metrics.*.thresholds` ëŠ” Pass/Fair/Poor ê²Œì´ì§€ ê¸°ì¤€ì´ì LLM-OV í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë©ë‹ˆë‹¤.
- `efficiency` ë¸”ë¡ì€ ì„±ëŠ¥ ì¹´ë“œì˜ ì´ìƒì¹˜ ê°ì§€ ê·œì¹™ì„ ì§€ì •í•©ë‹ˆë‹¤.
- `advanced.llm_judge` ëŠ” LLM-PTì™€ LLM-OVê°€ ì‚¬ìš©í•  ëª¨ë¸/íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.

í˜ë¥´ì†Œë‚˜/ë³€í˜• ì „ëµì€ `configs/input.yaml` ì— ì •ì˜ë˜ë©°, LLM-PT ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ìë™ìœ¼ë¡œ ì£¼ì…ë©ë‹ˆë‹¤.

## Tips & Troubleshooting

- `per_trace_analysis/per_trace.jsonl` ì´ ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤. í•„ìš” ì‹œ `--per-trace` ë¡œ ì ˆëŒ€ê²½ë¡œë¥¼ ë„˜ê¸°ì„¸ìš”.
- ë°˜ë³µ ì‹¤í–‰ ì‹œ `--overwrite` ë¥¼ ì¶”ê°€í•˜ë©´ ê¸°ì¡´ `evaluation_report` ë””ë ‰í„°ë¦¬ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- `--output relative/path` ë¡œ ëª…ì‹œí•˜ë©´ ì‹¤í—˜ í´ë” ë‚´ë¶€ì— ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œë¥¼ ì—¬ëŸ¬ ê°œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ: `eval_model_a`, `eval_model_b`).
- ë³´ê³ ì„œë¥¼ ê³µìœ í•  ë•ŒëŠ” `report.html` íŒŒì¼ë§Œ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤. ì™¸ë¶€ CDN ìš”ì²­ì´ ì—†ìœ¼ë¯€ë¡œ ì˜¤í”„ë¼ì¸ ë·°ì‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- íŒŒì´í”„ë¼ì¸ ë¡œê·¸ë¥¼ ìì„¸íˆ ë³´ê³  ì‹¶ì„ ë•ŒëŠ” `--verbose` ë¡œ ì‹¤í–‰í•˜ì„¸ìš”. Stage 1~5 ì§„í–‰ ìƒí™©ì´ ëª¨ë‘ ì¶œë ¥ë©ë‹ˆë‹¤.

ë” í° ì›Œí¬í”Œë¡œìš° ì˜ˆì‹œëŠ” [First Experiment Guide](/cli/getting-started/first-experiment) ì™€ [Basic Workflow](/cli/workflows/basic-workflow) ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
